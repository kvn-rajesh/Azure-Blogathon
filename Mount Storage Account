Code Snippet for Storage account to be mounted to Azure Databricks workspace.
storageaccount="<<name_of_storare_account>>"
account_key="<<account_key_of_storare_account>>"

containername="Flaviadataset"
mountname=containername

# COMMAND ----------

# MAGIC %md #1. Mount blob storage

# COMMAND ----------

if any(mount.mountPoint == "/mnt/" + mountname for mount in dbutils.fs.mounts()):
  print ("directory " + "/mnt/" + mountname + " is already mounted")
else:
  print ("In case you have a cluster with 0 workers, you need to cancell statement manually after 30 seconds. This is because a spark job is started, which cannot be executed since there are 0 workers. However, the storage is mounted, which can be verified by rerunning cell")
  dbutils.fs.mount(
  source = "wasbs://" + containername + "@" + storageaccount + ".blob.core.windows.net",
  mount_point = "/mnt/" + mountname,
  extra_configs = {"fs.azure.account.key." + storageaccount +".blob.core.windows.net":account_key})

# COMMAND ----------

# MAGIC %md #2. Unzip pictures

# COMMAND ----------


datafile = "flavia.zip"
datafile_dbfs = os.path.join("/dbfs/mnt/" + mountname, datafile)

print ("unzipping takes approximatelly 2 minutes")
zip_ref = zipfile.ZipFile(datafile_dbfs, 'r')
zip_ref.extractall("/dbfs/mnt/" + mountname)
zip_ref.close()

# COMMAND ----------

# MAGIC %sh
# MAGIC ls /dbfs/mnt/flavia

# COMMAND ----------

# MAGIC %md #3. Show pictures

# COMMAND ----------


