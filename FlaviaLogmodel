Code Snippet for Flavia Log Model
The steps implemented are
Log metrics of models that was trained on Flavia leaf pictures
Register best model (trained with Flavia pictures)

ws = Workspace(workspace_name = workspace,
               subscription_id = subscription_id,
               resource_group = resource_grp)

ws.get_details()

# COMMAND ----------

# MAGIC %md #####  Load models from disk where it was stored 
# COMMAND ----------


from keras.models import load_model

#path= '/dbfs/Flavia/models/'
model2000path = path + par_model2000_name
modelallpath = path + par_modelall_name

model2000 = load_model(model2000path)
modelall = load_model(modelallpath)

# COMMAND ----------

model2000.summary()

# COMMAND ----------

# MAGIC %md ##### Get testdate to regenerate metrics

# COMMAND ----------

from keras.datasets import flavia
num_classes = 10
# The data, shuffled and split between train and test sets:
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
#2
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
#3
x_train /= 255
x_test /= 255

# COMMAND ----------

# MAGIC %md #####Create new experiment in Azure ML service workspace and add both models

# COMMAND ----------

# upload the serialized model into run history record
#mdl, ext = par_model_name.split(".")
#model_zip = mdl + ".zip"
#shutil.make_archive('/dbfs/'+ mdl, 'zip', path)
# start a training run by defining an experiment
myexperiment = Experiment(ws, par_experiment_name)
run = myexperiment.start_logging()

score2000 = model2000.evaluate(x_test, y_test, verbose=0)
scoreall = modelall.evaluate(x_test, y_test, verbose=0)

run.log_list("Test accuracy 2000 pics, all pics", [score2000[1], scoreall[1]])
run.log_list("Test loss 2000 pics, all pics", [score2000[0], scoreall[0]])

run.upload_file("outputs/" + par_model2000_name, model2000path)
run.upload_file("outputs/" + par_modelall_name, modelallpath)

run.complete()
run_id = run.id
print ("run id:", run_id)

# COMMAND ----------

# MAGIC %md #2. Register best model (trained with 60000 pictures)

# COMMAND ----------

registermodelall = Model.register(
    model_path=modelallpath,  # this points to a local file
    model_name=par_modelall_name,  # this is the name the model is registered as
    tags={"area": "spark", "type": "deeplearning", "run_id": run_id},
    description="Keras deeplearning, all pictures",
    workspace=ws,
)
print("Model registered: {} \nModel Description: {} \nModel Version: {}".format(registermodelall.name, registermodelall.description, registermodelall.version))
